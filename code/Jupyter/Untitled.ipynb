{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9c7644957cef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcanny\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdsu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhistogram\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/edge_detection/bcdn/BDCN/code/network.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import sys\n",
    "# import cv2\n",
    "bdcn_path = 'home/kohyoung/edge_detection/bcdn/BDCN'\n",
    "sys.path.append(bdcn_path)\n",
    "from utils import *\n",
    "from canny import *\n",
    "from thresh import *\n",
    "from network import *\n",
    "from dsu import *\n",
    "from histogram import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Load an example image\n",
    "root = '/home/kohyoung/edge_detection/Data/Mobile - Black board - Shield - Narrow gaps 5'\n",
    "model_root = '/home/kohyoung/edge_detection/bcdn/final-model/bdcn_pretrained_on_bsds500.pth'\n",
    "array_index=3\n",
    "\n",
    "image_dir =root+'/bmps/'\n",
    "height_dir = root+'/height maps/RAW/'\n",
    "img_arr=[]\n",
    "\n",
    "\n",
    "raws_list = sorted(os.listdir(height_dir))\n",
    "image_list = sorted(os.listdir(image_dir))\n",
    "count=0\n",
    "data_arr = []\n",
    "\n",
    "#Load data and images in an array\n",
    "for i in range(len(raws_list)):\n",
    "    name=raws_list[i].split('.')[0]\n",
    "    init_name = name[-7:]\n",
    "    img_arr.append([])\n",
    "    \n",
    "    #Load the top mid and bottom image\n",
    "    #and apply adaptive histogram equalization\n",
    "    img = cv.imread(image_dir+init_name+'-Top.bmp')\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    img_arr[i].append(img_adapteq)\n",
    "    \n",
    "    img = cv.imread(image_dir+init_name+'-Mid.bmp')\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    img_arr[i].append(img_adapteq)\n",
    "    \n",
    "    img = cv.imread(image_dir+init_name+'-Bot.bmp')\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    img_arr[i].append(img_adapteq)\n",
    "                      \n",
    "    # prevent overlap of y-axis labels\n",
    "    # plt.subplots_adjust(wspace=0.4)\n",
    "    # plt.show()\n",
    "   \n",
    "    #Load Height Data and reshape it to the size of the image\n",
    "    with open(height_dir+raws_list[i],'rb') as f:\n",
    "        data = np.fromfile(f, dtype=np.float32)\n",
    "        print(len(data))\n",
    "        array = np.reshape(data, img.shape[:2])\n",
    "        data_arr.append(array)\n",
    "\n",
    "\n",
    "threshed_map_low=[]\n",
    "threshed_map_high=[]\n",
    "\n",
    "height_map = data_arr[array_index]\n",
    "#Normalize Height data\n",
    "height_map = np.uint8(((height_map-height_map.min())/height_map.max())*255)\n",
    "ret,thr_low,thr_high = thresh_data(height_map)\n",
    "\n",
    "#Get edges from running neural network on the data\n",
    "res,combined_edge = get_edges_network(img_arr[array_index],model_root)\n",
    "# morphed_edge = apply_morphing(combined_edge)\n",
    "\n",
    "#get contours on the results fo the networks\n",
    "print(combined_edge.shape)\n",
    "contours_edges,contour_canny,rect_list_edges = get_bounding_box(edge_map\\\n",
    "    =combined_edge,color_map=(0,0,255),area_upper_lim=50000,area_lower_lim=100)\n",
    "#Get bounding boxes from height data \n",
    "rect_list_height = iterative_thresh(data_arr[array_index])\n",
    "\n",
    "#Get canny edges for finer details\n",
    "edges = find_canny(img_arr)\n",
    "canny_edge_arr = canny_detector(edges)\n",
    "\n",
    "#Refine edge detection results\n",
    "combined_list = refine_bb(rect_list_height)\n",
    "contours_edges,contour_canny,rect_list_edges = get_bounding_box(canny_edge_arr[array_index],\\\n",
    "    color_map=(0,0,255),area_upper_lim=20000,area_lower_lim=100)\n",
    "\n",
    "#Save the processed data\n",
    "save_dir ='../Processed_data/'\n",
    "save_file = save_dir+root.split('/')[-1]+'.txt'\n",
    "value_dict = {}\n",
    "value_dict['boxes']=combined_list\n",
    "value_dict['image']=img_arr[array_index][1] \n",
    "if value_dict:\n",
    "    with open(save_file, 'wb') as dict_items_save:\n",
    "        pickle.dump(value_dict, dict_items_save)\n",
    "\n",
    "\n",
    "# #Draw edges on the image data for visualization\n",
    "# draw_rect(rect_list_edges,deepcopy(img_arr[array_index][1]))\n",
    "# #   print(len(rect_list_edges),len(rect_list_height))\n",
    "# draw_rect(combined_list,deepcopy(img_arr[array_index][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit ('py36to02': conda)",
   "language": "python",
   "name": "python36664bitpy36to02conda0d17bbf6f33e46ea8589fbd6724fd9ff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
